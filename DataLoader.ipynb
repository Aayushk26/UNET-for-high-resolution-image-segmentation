{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOME INFORMATION ABOUT MY TRAINING DATASET.\n",
    "# I have RGB images as my input images.\n",
    "# The ground truth is a triple channel black and white image.\n",
    "# So I convert the ground truth to single channel image and the ouput is a single channel #segmentation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "import csv\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_set(Dataset):\n",
    "    def __init__(self , csv_file  , root_dir , transform = None ):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations) \n",
    "    \n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        try:\n",
    "            img_path = os.path.join(self.root_dir , self.annotations.iloc[index , 0])\n",
    "            image = Image.open(img_path )\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "      \n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        return image\n",
    "\n",
    "#The batch size chosen here is 1. This reduces the GPU usage.\n",
    "batch_size = 1\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are creating a csv file which will contain the names of the images in your training data.\n",
    "#This csv file will be used to fetch the data and add it tooe dataloader.\n",
    "with open('image_annotation.csv', 'w', newline='') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    \n",
    "    \n",
    "    for filename in os.listdir(r\"...path_to_your_training_dataset...\"):\n",
    "        \n",
    "            data.append(filename)\n",
    "            writer.writerow(data)\n",
    "            data=[]\n",
    "writeFile.close()\n",
    "\n",
    "with open('label_annotation.csv', 'w', newline='') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    \n",
    "    \n",
    "    for filename in os.listdir(r\"...path_to_your_groundTruth_dataset...\"):\n",
    "        \n",
    "            data.append(filename)\n",
    "            writer.writerow(data)\n",
    "            data=[]\n",
    "writeFile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage() , \n",
    "    transforms.Resize((1024 , 1024)) ,\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "my_transforms_grayscale = transforms.Compose([\n",
    "    transforms.ToPILImage() , \n",
    "    transforms.Resize((1024 , 1024)) , \n",
    "    transforms.Grayscale(1) , \n",
    "    transforms.ToTensor()    \n",
    "])\n",
    "\n",
    "colored_dataset = data_set(csv_file = \"image_annotation.csv\" , root_dir = \"...path_to_your_training_dataset...\" , \n",
    "                          transform = my_transforms)\n",
    "\n",
    "grayscale_dataset = data_set(csv_file = \"label_annotation.csv\" , root_dir = \"...path_to_your_training_dataset...\" , \n",
    "                             transform = my_transforms_grayscale)\n",
    "\n",
    "image_loader = DataLoader(dataset = colored_dataset , batch_size = batch_size , shuffle = False)\n",
    "grayscale_loader = DataLoader(dataset = grayscale_dataset , batch_size = batch_size , shuffle = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}